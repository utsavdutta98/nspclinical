{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:35:42.200025Z","iopub.execute_input":"2021-09-17T22:35:42.200431Z","iopub.status.idle":"2021-09-17T22:35:49.201349Z","shell.execute_reply.started":"2021-09-17T22:35:42.20032Z","shell.execute_reply":"2021-09-17T22:35:49.200337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport re\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:35:49.202968Z","iopub.execute_input":"2021-09-17T22:35:49.203297Z","iopub.status.idle":"2021-09-17T22:35:50.533742Z","shell.execute_reply.started":"2021-09-17T22:35:49.203266Z","shell.execute_reply":"2021-09-17T22:35:50.532933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import Bio_ClinicalBERT model from huggingface\n\nfrom transformers import AutoTokenizer, AutoModel\n\ntokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\nBioClinicalBert = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:35:50.535497Z","iopub.execute_input":"2021-09-17T22:35:50.535823Z","iopub.status.idle":"2021-09-17T22:36:18.347035Z","shell.execute_reply.started":"2021-09-17T22:35:50.535789Z","shell.execute_reply":"2021-09-17T22:36:18.345977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import pubmed abstracts data into a dataframe\n\ndata = pd.read_csv('/kaggle/input/pubmed/pubmed_abstracts.csv')","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:36:18.348849Z","iopub.execute_input":"2021-09-17T22:36:18.349215Z","iopub.status.idle":"2021-09-17T22:36:19.641556Z","shell.execute_reply.started":"2021-09-17T22:36:18.349175Z","shell.execute_reply":"2021-09-17T22:36:19.640707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corpus = data['neuroprosthetics'].dropna().values.tolist() + data['covid_19'].dropna().values.tolist() + data['deep_learning'].dropna().values.tolist() + data['human_connectome'].dropna().values.tolist() + data['brain_machine_interfaces'].dropna().values.tolist()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:36:19.642867Z","iopub.execute_input":"2021-09-17T22:36:19.643218Z","iopub.status.idle":"2021-09-17T22:36:19.661462Z","shell.execute_reply.started":"2021-09-17T22:36:19.643182Z","shell.execute_reply":"2021-09-17T22:36:19.660618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build text library\ntext = []\n\n# Iterate over text snippets\nfor line in corpus:\n\n  try:\n\n    # Remove abstracts which only contain title\n    if not re.match(\".*\\[\\]\",line):\n\n      # Append only abstract text\n      text.append((line[line.find(\"[\")+1:line.find(\"]\")])[1:-2])\n\n  except:\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:36:19.66276Z","iopub.execute_input":"2021-09-17T22:36:19.663112Z","iopub.status.idle":"2021-09-17T22:36:19.787386Z","shell.execute_reply.started":"2021-09-17T22:36:19.663077Z","shell.execute_reply":"2021-09-17T22:36:19.78659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_inputs(text):\n\n  # Create list of sentences\n  sentences_a = []\n  sentences_b = []\n  labels = []\n\n  # Create a list of paragraphs, split by full-stop mark\n  bag = []\n\n  for paragraph in text:\n    bag.append(paragraph.split('.'))\n\n  ListOfSentences = [x for sublist in bag for x in sublist]\n\n  # Iterate over each abstract\n  for para in bag:\n\n    # Abstract should have more than 1 line\n    if len(para) > 1:\n\n      # Choose a random sentence \n      start_key = random.randint(0,len(para)-2)\n      sentences_a.append(para[start_key])\n\n      # Append random sentence 50% of the time\n      if random.random() > 0.5:\n        sentences_b.append(ListOfSentences[random.randint(0,len(ListOfSentences) - 1)])\n        labels.append(0)\n\n      # Append next sentence other 50% of the time\n      else:\n        sentences_b.append(para[start_key + 1])\n        labels.append(1)\n\n # BERT Tokenizer, 512 length sentences\n  inputs = tokenizer(sentences_a,sentences_b,\n                    return_tensors='pt',\n                    max_length = 512,\n                    truncation = True,\n                    padding = 'max_length')\n  # Add a labels section\n  inputs['labels'] = torch.LongTensor([labels]).T\n\n  return inputs ","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:36:19.788642Z","iopub.execute_input":"2021-09-17T22:36:19.788978Z","iopub.status.idle":"2021-09-17T22:36:19.797024Z","shell.execute_reply.started":"2021-09-17T22:36:19.788943Z","shell.execute_reply":"2021-09-17T22:36:19.796105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of usable abstracts\nlen(text)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:36:19.799242Z","iopub.execute_input":"2021-09-17T22:36:19.799622Z","iopub.status.idle":"2021-09-17T22:36:19.813244Z","shell.execute_reply.started":"2021-09-17T22:36:19.799586Z","shell.execute_reply":"2021-09-17T22:36:19.812457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shuffle randomly, to intermix topics\nrandom.shuffle(text)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:36:19.816204Z","iopub.execute_input":"2021-09-17T22:36:19.816545Z","iopub.status.idle":"2021-09-17T22:36:19.845732Z","shell.execute_reply.started":"2021-09-17T22:36:19.816508Z","shell.execute_reply":"2021-09-17T22:36:19.844942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split into train, valid and test\ntrain = text[:20000]\nvalid = text[20001:25000]\ntest = text[25001:]","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:36:19.847001Z","iopub.execute_input":"2021-09-17T22:36:19.847472Z","iopub.status.idle":"2021-09-17T22:36:19.855319Z","shell.execute_reply.started":"2021-09-17T22:36:19.847439Z","shell.execute_reply":"2021-09-17T22:36:19.854538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build PyTorch dataset class instance for clinical text\nclass MedTextDataset(torch.utils.data.Dataset):\n\n  def __init__(self,text):\n    self.text = text\n  \n  def __len__(self):\n    return len(self.text)\n\n  def __getitem__(self,index):\n    dictionary = create_inputs(self.text[index])\n    return {key: dictionary[key] for key in dictionary}","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:36:47.513099Z","iopub.execute_input":"2021-09-17T22:36:47.513457Z","iopub.status.idle":"2021-09-17T22:36:47.518448Z","shell.execute_reply.started":"2021-09-17T22:36:47.51342Z","shell.execute_reply":"2021-09-17T22:36:47.517626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Instantiate\ntrain_dataset = MedTextDataset(train)\nvalid_dataset = MedTextDataset(valid)\ntest_dataset = MedTextDataset(test)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:36:48.537214Z","iopub.execute_input":"2021-09-17T22:36:48.537568Z","iopub.status.idle":"2021-09-17T22:36:48.541733Z","shell.execute_reply.started":"2021-09-17T22:36:48.537537Z","shell.execute_reply":"2021-09-17T22:36:48.540746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build dataloader class object\n\nBATCH_SIZE = 32\ntrainloader = torch.utils.data.DataLoader(train_dataset,batch_size = BATCH_SIZE, shuffle = True)\nvalidloader = torch.utils.data.DataLoader(valid_dataset,batch_size = BATCH_SIZE, shuffle = True)\ntestloader = torch.utils.data.DataLoader(test_dataset,batch_size = BATCH_SIZE, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:36:51.247431Z","iopub.execute_input":"2021-09-17T22:36:51.247802Z","iopub.status.idle":"2021-09-17T22:36:51.253815Z","shell.execute_reply.started":"2021-09-17T22:36:51.247766Z","shell.execute_reply":"2021-09-17T22:36:51.252606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Send to 'GPU'\ndevice = torch.device('cuda')","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:36:52.399815Z","iopub.execute_input":"2021-09-17T22:36:52.400155Z","iopub.status.idle":"2021-09-17T22:36:52.404647Z","shell.execute_reply.started":"2021-09-17T22:36:52.400124Z","shell.execute_reply":"2021-09-17T22:36:52.403544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build BERT Model + Linear Layer + Sigmoid\nclass BioClinicalBertNSP(nn.Module):\n\n  def __init__(self):\n    super().__init__()\n\n    # Create models\n    self.bioclinicalbert = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n    self.linear = nn.Linear(768,1)\n  \n  def forward(self,input_ids,attention_mask,token_type_ids):\n\n    # Pass through layers\n    outputs = self.bioclinicalbert(input_ids, attention_mask = attention_mask,token_type_ids = token_type_ids)\n\n    outputs = outputs['last_hidden_state']\n    outputs = torch.mean(outputs, dim = 1)\n\n    outputs = self.linear(outputs)\n    outputs = F.sigmoid(outputs)\n\n    return outputs","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:36:53.670938Z","iopub.execute_input":"2021-09-17T22:36:53.67126Z","iopub.status.idle":"2021-09-17T22:36:53.680134Z","shell.execute_reply.started":"2021-09-17T22:36:53.671229Z","shell.execute_reply":"2021-09-17T22:36:53.679303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%config Completer.use_jedi = True","metadata":{"execution":{"iopub.status.busy":"2021-09-05T18:57:30.311513Z","iopub.execute_input":"2021-09-05T18:57:30.311834Z","iopub.status.idle":"2021-09-05T18:57:30.325643Z","shell.execute_reply.started":"2021-09-05T18:57:30.311805Z","shell.execute_reply":"2021-09-05T18:57:30.324799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_accuracy(model, data_loader, device):\n    \n    model.eval()\n\n    with torch.no_grad():\n\n        correct_pred, num_examples = 0, 0\n\n        for batch_idx, batch in enumerate(data_loader):\n\n            ### Prepare data\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            labels = batch['labels'].to(device)\n            \n            outputs = model(input_ids, token_type_ids = token_type_ids, attention_mask=attention_mask)\n\n            predicted_labels = torch.round(outputs)\n\n            num_examples += labels.size(0)\n\n            correct_pred += (predicted_labels == labels).sum()\n    return correct_pred.float()/num_examples * 100","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:37:03.299312Z","iopub.execute_input":"2021-09-17T22:37:03.299676Z","iopub.status.idle":"2021-09-17T22:37:03.306639Z","shell.execute_reply.started":"2021-09-17T22:37:03.299644Z","shell.execute_reply":"2021-09-17T22:37:03.305449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = BioClinicalBertNSP()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:37:04.472216Z","iopub.execute_input":"2021-09-17T22:37:04.472591Z","iopub.status.idle":"2021-09-17T22:37:06.860214Z","shell.execute_reply.started":"2021-09-17T22:37:04.472559Z","shell.execute_reply":"2021-09-17T22:37:06.859427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name,param in model.named_parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:37:07.917559Z","iopub.execute_input":"2021-09-17T22:37:07.917872Z","iopub.status.idle":"2021-09-17T22:37:07.924354Z","shell.execute_reply.started":"2021-09-17T22:37:07.917843Z","shell.execute_reply":"2021-09-17T22:37:07.923305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.linear.weight.requires_grad = True\nmodel.linear.bias.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:37:08.272261Z","iopub.execute_input":"2021-09-17T22:37:08.272724Z","iopub.status.idle":"2021-09-17T22:37:08.280183Z","shell.execute_reply.started":"2021-09-17T22:37:08.272686Z","shell.execute_reply":"2021-09-17T22:37:08.279394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, param in model.named_parameters():\n    if (param.requires_grad == True):\n        print(name,param.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:37:13.110799Z","iopub.execute_input":"2021-09-17T22:37:13.111134Z","iopub.status.idle":"2021-09-17T22:37:13.119144Z","shell.execute_reply.started":"2021-09-17T22:37:13.111103Z","shell.execute_reply":"2021-09-17T22:37:13.118018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T21:00:09.071012Z","iopub.execute_input":"2021-09-05T21:00:09.071365Z","iopub.status.idle":"2021-09-05T21:00:09.191991Z","shell.execute_reply.started":"2021-09-05T21:00:09.07133Z","shell.execute_reply":"2021-09-05T21:00:09.191224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW\noptim = AdamW(model.parameters(), lr = 1e-5)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:37:16.435239Z","iopub.execute_input":"2021-09-17T22:37:16.435598Z","iopub.status.idle":"2021-09-17T22:37:16.449349Z","shell.execute_reply.started":"2021-09-17T22:37:16.435567Z","shell.execute_reply":"2021-09-17T22:37:16.447242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\nNUM_EPOCHS = 2\n\ncriterion = nn.BCELoss()\n\nfor epoch in range(NUM_EPOCHS):\n    \n    model.train()\n    \n    for batch_idx, batch in enumerate(trainloader):\n        \n      optim.zero_grad()\n\n      input_ids = batch['input_ids'].to(device)\n      token_type_ids = batch['token_type_ids'].to(device)\n      attention_mask = batch['attention_mask'].to(device)\n      labels = batch['labels'].to(device)\n    \n\n      output = model(input_ids, \n                    token_type_ids = token_type_ids, \n                    attention_mask = attention_mask)\n      \n      loss = criterion(output,labels.float())\n      loss.backward()\n\n      if not batch_idx % 50:\n\n        print(f\"epoch number = {epoch}\", f\"batch {batch_idx}/{len(trainloader)}\", f\"loss = {round(loss.item(),2)}\")\n\n      optim.step()\n            \n    model.eval()\n\n    with torch.set_grad_enabled(False):\n        print(f'training accuracy: '\n              f'{compute_accuracy(model, trainloader, device):.2f}%'\n              f'\\nvalid accuracy: '\n              f'{compute_accuracy(model, validloader, device):.2f}%')\n        \n    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n    \nprint(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\nprint(f'Test accuracy: {compute_accuracy(model, testloader, device):.2f}%')","metadata":{"execution":{"iopub.status.busy":"2021-09-17T22:37:18.102042Z","iopub.execute_input":"2021-09-17T22:37:18.102398Z","iopub.status.idle":"2021-09-17T22:37:18.773579Z","shell.execute_reply.started":"2021-09-17T22:37:18.102353Z","shell.execute_reply":"2021-09-17T22:37:18.768842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"compute_accuracy(model, testloader, device)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T20:30:39.228752Z","iopub.execute_input":"2021-09-05T20:30:39.229074Z","iopub.status.idle":"2021-09-05T20:31:03.52206Z","shell.execute_reply.started":"2021-09-05T20:30:39.229042Z","shell.execute_reply":"2021-09-05T20:31:03.521242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}